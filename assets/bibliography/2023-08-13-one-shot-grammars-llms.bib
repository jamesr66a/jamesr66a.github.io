@misc{geng2023flexible,
      title={Flexible Grammar-Based Constrained Decoding for Language Models},
      author={Saibo Geng and Martin Josifosky and Maxime Peyrard and Robert West},
      year={2023},
      eprint={2305.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shin2021constrained,
      title={Constrained Language Models Yield Few-Shot Semantic Parsers},
      author={Richard Shin and Christopher H. Lin and Sam Thomson and Charles Chen and Subhro Roy and Emmanouil Antonios Platanios and Adam Pauls and Dan Klein and Jason Eisner and Benjamin Van Durme},
      year={2021},
      eprint={2104.08768},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{scholak2021picard,
      title={PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models},
      author={Torsten Scholak and Nathan Schucher and Dzmitry Bahdanau},
      year={2021},
      eprint={2109.05093},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023grammar,
      title={Grammar Prompting for Domain-Specific Language Generation with Large Language Models},
      author={Bailin Wang and Zi Wang and Xuezhi Wang and Yuan Cao and Rif A. Saurous and Yoon Kim},
      year={2023},
      eprint={2305.19234},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{heyueya2023solving,
      title={Solving Math Word Problems by Combining Language Models With Symbolic Solvers},
      author={Joy He-Yueya and Gabriel Poesia and Rose E. Wang and Noah D. Goodman},
      year={2023},
      eprint={2304.09102},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lyu2023faithful,
      title={Faithful Chain-of-Thought Reasoning},
      author={Qing Lyu and Shreya Havaldar and Adam Stein and Li Zhang and Delip Rao and Eric Wong and Marianna Apidianaki and Chris Callison-Burch},
      year={2023},
      eprint={2301.13379},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hu2023chainofsymbol,
      title={Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models},
      author={Hanxu Hu and Hongyuan Lu and Huajian Zhang and Wai Lam and Yue Zhang},
      year={2023},
      eprint={2305.10276},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ye2023satisfiabilityaided,
      title={Satisfiability-Aided Language Models Using Declarative Prompting},
      author={Xi Ye and Qiaochu Chen and Isil Dillig and Greg Durrett},
      year={2023},
      eprint={2305.09656},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{pan2023logiclm,
      title={Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
      author={Liangming Pan and Alon Albalak and Xinyi Wang and William Yang Wang},
      year={2023},
      eprint={2305.12295},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schick2023toolformer,
      title={Toolformer: Language Models Can Teach Themselves to Use Tools},
      author={Timo Schick and Jane Dwivedi-Yu and Roberto Dess√¨ and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
      year={2023},
      eprint={2302.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{poesia2022synchromesh,
      title={Synchromesh: Reliable code generation from pre-trained language models},
      author={Gabriel Poesia and Oleksandr Polozov and Vu Le and Ashish Tiwari and Gustavo Soares and Christopher Meek and Sumit Gulwani},
      year={2022},
      eprint={2201.11227},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{jiang-etal-2016-unsupervised,
    title = "Unsupervised Neural Dependency Parsing",
    author = "Jiang, Yong  and
      Han, Wenjuan  and
      Tu, Kewei",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1073",
    doi = "10.18653/v1/D16-1073",
    pages = "763--771",
}

@misc{dyer2016recurrent,
      title={Recurrent Neural Network Grammars},
      author={Chris Dyer and Adhiguna Kuncoro and Miguel Ballesteros and Noah A. Smith},
      year={2016},
      eprint={1602.07776},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{kim-etal-2019-unsupervised,
    title = "Unsupervised Recurrent Neural Network Grammars",
    author = "Kim, Yoon  and
      Rush, Alexander  and
      Yu, Lei  and
      Kuncoro, Adhiguna  and
      Dyer, Chris  and
      Melis, G{\'a}bor",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1114",
    doi = "10.18653/v1/N19-1114",
    pages = "1105--1117",
    abstract = "Recurrent neural network grammars (RNNG) are generative models of language which jointly model syntax and surface structure by incrementally generating a syntax tree and sentence in a top-down, left-to-right order. Supervised RNNGs achieve strong language modeling and parsing performance, but require an annotated corpus of parse trees. In this work, we experiment with unsupervised learning of RNNGs. Since directly marginalizing over the space of latent trees is intractable, we instead apply amortized variational inference. To maximize the evidence lower bound, we develop an inference network parameterized as a neural CRF constituency parser. On language modeling, unsupervised RNNGs perform as well their supervised counterparts on benchmarks in English and Chinese. On constituency grammar induction, they are competitive with recent neural language models that induce tree structures from words through attention mechanisms.",
}

@inproceedings{kim-etal-2019-compound,
    title = "Compound Probabilistic Context-Free Grammars for Grammar Induction",
    author = "Kim, Yoon  and
      Dyer, Chris  and
      Rush, Alexander",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1228",
    doi = "10.18653/v1/P19-1228",
    pages = "2369--2385",
    abstract = "We study a formalization of the grammar induction problem that models sentences as being generated by a compound probabilistic context free grammar. In contrast to traditional formulations which learn a single stochastic grammar, our context-free rule probabilities are modulated by a per-sentence continuous latent variable, which induces marginal dependencies beyond the traditional context-free assumptions. Inference in this context-dependent grammar is performed by collapsed variational inference, in which an amortized variational posterior is placed on the continuous variable, and the latent trees are marginalized with dynamic programming. Experiments on English and Chinese show the effectiveness of our approach compared to recent state-of-the-art methods for grammar induction from words with neural language models.",
}

@misc{kim2021sequencetosequence,
      title={Sequence-to-Sequence Learning with Latent Neural Grammars},
      author={Yoon Kim},
      year={2021},
      eprint={2109.01135},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{friedman2022finding,
      title={Finding Dataset Shortcuts with Grammar Induction},
      author={Dan Friedman and Alexander Wettig and Danqi Chen},
      year={2022},
      eprint={2210.11560},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2022hierarchical,
      title={Hierarchical Phrase-based Sequence-to-Sequence Learning},
      author={Bailin Wang and Ivan Titov and Jacob Andreas and Yoon Kim},
      year={2022},
      eprint={2211.07906},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
